import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, Input, Conv1D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import Huber

# Load dataset
file_path = 'merged_crop_weather.csv'
data = pd.read_csv(file_path)

# One-Hot Encoding for crop types
data = pd.get_dummies(data, columns=['Item'])

# Convert all columns to float32 to avoid dtype issues
data = data.astype('float32')

# Apply log transformation to reduce skewness
data['Value'] = np.log1p(data['Value'])  # log(1 + Value)

# Handle missing values using KNN Imputation
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)
data.iloc[:, :] = imputer.fit_transform(data)

# Feature Selection
num_features = ['Year', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'PRECTOTCORR_SUM', 'RH2M', 'WS2M', 'GWETTOP', 'GWETROOT', 'GWETPROF']
item_features = [col for col in data.columns if col.startswith('Item_')]
X = data[num_features + item_features]
y = data['Value']

# Scaling (Robust for weather features, Standard for Year & Target)
scaler_X = RobustScaler()
scaler_y = StandardScaler()
X_scaled = X.copy()
X_scaled[num_features] = scaler_X.fit_transform(X[num_features])
y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))

# Data Augmentation - Adding small noise
def augment_data(X, y, noise_factor=0.01):
    noise = noise_factor * np.random.normal(size=X.shape)
    X_aug = X + noise
    return np.clip(X_aug, X.min(axis=0).values, X.max(axis=0).values), y

X_scaled, y_scaled = augment_data(X_scaled, y_scaled)

# Train-test split
train_size = int(len(X_scaled) * 0.8)
X_train, X_test = X_scaled.iloc[:train_size], X_scaled.iloc[train_size:]
y_train, y_test = y_scaled[:train_size], y_scaled[train_size:]

# Convert y_train and y_test to NumPy arrays
y_train = np.array(y_train).reshape(-1, 1)
y_test = np.array(y_test).reshape(-1, 1)

# Reshape for CNN-LSTM
X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

# Model Architecture: CNN + Bidirectional LSTM
model = Sequential([
    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)),
    Bidirectional(LSTM(128, activation='relu', return_sequences=True)),
    Dropout(0.3),
    Bidirectional(LSTM(64, activation='relu', return_sequences=False)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(1)
])

# Compile model with Huber Loss
model.compile(optimizer=Adam(learning_rate=0.002), loss=Huber(delta=1.0), metrics=['mae'])

# Train the model
history = model.fit(
    X_train_reshaped, y_train,
    epochs=500, batch_size=16,
    validation_data=(X_test_reshaped, y_test),
    verbose=2
)

# Predict
y_pred_scaled = model.predict(X_test_reshaped)

# Inverse transform predictions
y_test_actual = scaler_y.inverse_transform(y_test)
y_pred_rescaled = scaler_y.inverse_transform(y_pred_scaled)

# Calculate metrics
mse = mean_squared_error(y_test_actual, y_pred_rescaled)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_actual, y_pred_rescaled)
mape = np.mean(np.abs((y_test_actual - y_pred_rescaled) / y_test_actual)) * 100
r2 = r2_score(y_test_actual, y_pred_rescaled)
ev_score = explained_variance_score(y_test_actual, y_pred_rescaled)
accuracy = 100 - mape

# Print results
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print(f"RÂ² Score: {r2:.2f}")
print(f"Explained Variance Score: {ev_score:.2f}")
print(f"Model Accuracy: {accuracy:.2f}%")

# Plot Actual vs Predicted Values
plt.figure(figsize=(10, 6))
plt.plot(y_test_actual, label="Actual Values", color='blue')
plt.plot(y_pred_rescaled, label="Predicted Values", color='red', linestyle='--')
plt.title("Actual vs Predicted Crop Yield")
plt.xlabel("Time Steps")
plt.ylabel("Yield Value")
plt.legend()
plt.grid(True)
plt.show()
